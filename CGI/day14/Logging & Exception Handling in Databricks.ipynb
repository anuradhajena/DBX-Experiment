{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d625fb3-639a-4c13-8f8c-d6fb02fa19c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d67117-deaa-4826-8ebf-23dc708b61bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_file_path=\"s3://datamaster/logs/error_log.txt\"\n",
    "logging.basicConfig(file_name=log_file_path,level=logging.ERROR,format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d039064-f5cc-4023-984d-9868b0bf8e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_path=\"s3://datamaster/dataset\"\n",
    "files=dbutils.fs.ls(input_path)\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        print(f\"{file.name}\")\n",
    "        print(f\"Processing: {file.name}\")\n",
    "        df = spark.read.option(\"header\", True).csv(file.path)  # Could fail if file is not proper CSV\n",
    "        \n",
    "        # Basic validation\n",
    "        if \"order_id\" not in df.columns:\n",
    "            raise ValueError(f\"Missing required column 'order_id' in file {file.name}\")\n",
    "        \n",
    "        df.write.mode(\"overwrite\").saveAsTable(\"cgi_dev.naval_bronze.sales\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing file: {file.name} - {str(e)}\"\n",
    "        print(error_msg)\n",
    "        logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b09ca8b9-3b79-4647-88ef-2ba0ab899a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"dbfs:/tmp/datamaster/logs/error_log.txt\", \"s3://datamaster/logs/error_log.txt\", recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b53852a-2b5b-4490-bc42-b825686e1452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "/Volumes/cgi_dev/naval/customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f973de3-ec58-4156-b7ec-de7916e28f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_file_path=\"/Volumes/cgi_dev/naval/logs\"\n",
    "logging.basicConfig(file_name=log_file_path,level=logging.ERROR,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "input_path=\"s3://datamaster/dataset\"\n",
    "files=dbutils.fs.ls(input_path)\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        print(f\"Processing: {file.name}\")\n",
    "        df = spark.read.option(\"header\", True).csv(file.path)  # Could fail if file is not proper CSV\n",
    "        \n",
    "        # Basic validation\n",
    "        if \"id\" not in df.columns:\n",
    "            raise ValueError(f\"Missing required column 'order_id' in file {file.name}\")\n",
    "        \n",
    "        df.write.mode(\"overwrite\").saveAsTable(\"cgi_dev.naval_bronze.sales\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing file: {file.name} - {str(e)}\"\n",
    "        print(error_msg)\n",
    "        logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c349da9-34d1-4dd8-9117-0cf2bf0ccfe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Logging & Exception Handling in Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
